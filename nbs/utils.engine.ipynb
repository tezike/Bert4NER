{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from abc import ABC\n",
    "from fastprogress.fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Fitter(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def log(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def validate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BertFitter(Fitter):\n",
    "    def __init__(self, model, dataloaders, optimizer, metrics, device, log_file='training_log.txt',scheduler=None, trial=None):\n",
    "        self.model = model\n",
    "        self.train_dl, self.valid_dl = dataloaders[0], dataloaders[1]\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        if not os.path.exists(os.path.join('..', 'outputs')): os.makedirs(os.path.join('..', 'outputs'))\n",
    "        if os.path.exists(os.path.join('..', 'outputs', f'{log_file}')): \n",
    "            os.remove(os.path.join('..', 'outputs', f'{log_file}'))\n",
    "        self.log_file = os.path.join('..', 'outputs', f'{log_file}')\n",
    "        if not isinstance(metrics, (list, tuple)): \n",
    "            metrics = list(metrics)\n",
    "        self.metrics = metrics\n",
    "        self.device = device\n",
    "        self.trial = trial #for optuna\n",
    "        \n",
    "    def fit(self, epochs, return_metric=False, \n",
    "            monitor='epoch train_loss valid_loss tag_accuracy tag_f1_score pos_accuracy pos_f1_score time', \n",
    "            model_path=os.path.join('..', 'weights', 'model.pth'), show_graph=True):\n",
    "        self.model_path = model_path\n",
    "        self.log(f'{time.ctime()}')\n",
    "        self.log(f'Using device: {self.device}')\n",
    "        mb = master_bar(range(1, epochs+1)) #MAJOR\n",
    "        mb.write(monitor.split(),table=True)\n",
    "        \n",
    "        model = self.model.to(self.device)\n",
    "        optimizer = self.optimizer\n",
    "        best_metric = -np.inf\n",
    "        train_loss, valid_loss = 0, 0\n",
    "        valid_metric_0_tag, valid_metric_1_tag =  0, 0\n",
    "        valid_metric_0_pos, valid_metric_1_pos =  0, 0\n",
    "        train_loss_list, valid_loss_list = [], []\n",
    "        \n",
    "        for i_, epoch in enumerate(mb):\n",
    "            epoch_start = timeit.default_timer()\n",
    "            start = time.time()\n",
    "            self.log('-'*50)\n",
    "            self.log(f'Running Epoch #{epoch} {\"ðŸ”¥\"*epoch}')\n",
    "            self.log(f'{\"-\"*50} \\n')\n",
    "            self.log('TRAINING...')\n",
    "            for ind, batch in enumerate(progress_bar(self.train_dl, parent=mb)):\n",
    "                train_loss += self.train(batch, model, optimizer, self.device, self.scheduler)\n",
    "                if ind % 500 == 0:\n",
    "                    self.log(f'Batch: {ind}, Train loss: {train_loss/ len(self.train_dl)}')\n",
    "#                 break\n",
    "                mb.child.comment = f'{train_loss / (ind+1 * self.train_dl.batch_size):.3f}'\n",
    "            train_loss /= mb.child.total\n",
    "#             train_loss /= (ind+1)\n",
    "            train_loss_list.append(train_loss) #for graph\n",
    "            self.log(f'Training time: {round(time.time()-start, 2)} secs \\n')\n",
    "            \n",
    "            start = time.time()\n",
    "            self.log('EVALUATING...')\n",
    "            with torch.no_grad():\n",
    "                for ind, batch in enumerate(progress_bar(self.valid_dl, parent=mb)):\n",
    "                    valid_loss_, valid_metric_ = self.validate(batch, model, self.device)\n",
    "                    valid_loss += valid_loss_\n",
    "                    valid_metric_0_tag += valid_metric_[0]\n",
    "                    valid_metric_1_tag += valid_metric_[1]\n",
    "                    valid_metric_0_pos += valid_metric_[2]\n",
    "                    valid_metric_1_pos += valid_metric_[3]\n",
    "                    if ind % 500 == 0:\n",
    "                        self.log(f'Batch: {ind}, Valid loss: {valid_loss/ len(self.valid_dl)}')\n",
    "#                     break   \n",
    "                    mb.child.comment = f'{valid_loss / (ind+1 * self.train_dl.batch_size):.3f}'\n",
    "                \n",
    "                valid_loss /= mb.child.total\n",
    "#                 valid_loss /= (ind+1)\n",
    "#                 print(f\"valid_metric_0_tag: {valid_metric_0_tag}\")\n",
    "#                 print(f\"bs: {mb.child.total}\")\n",
    "                valid_metric_0_tag /= mb.child.total\n",
    "#                 valid_metric_0_tag /= (ind+1)\n",
    "                valid_metric_1_tag /= mb.child.total\n",
    "#                 valid_metric_1_tag /= (ind+1)\n",
    "#                 print(f\"valid_metric_0_pos: {valid_metric_0_pos}\")\n",
    "#                 print(f\"bs: {mb.child.total}\")\n",
    "                valid_metric_0_pos /= mb.child.total\n",
    "#                 valid_metric_0_pos /= (ind+1)\n",
    "                valid_metric_1_pos /= mb.child.total\n",
    "#                 valid_metric_1_pos /= (ind+1)\n",
    "                valid_loss_list.append(valid_loss) #for graph\n",
    "            \n",
    "            if valid_metric_0_pos > best_metric: #ie (f1_score > inf)\n",
    "                #             save model\n",
    "                if self.model_path is not None:\n",
    "                    if not os.path.exists(os.path.join('..', 'weights')): os.makedirs(os.path.join('..', 'weights'))\n",
    "                    self.log(f'Saving model weights at {self.model_path}')\n",
    "                    torch.save(model.state_dict(), self.model_path)\n",
    "                best_metric = valid_metric_0_pos\n",
    "                    \n",
    "            if self.trial is not None:\n",
    "                self.trial.report(best_metric, epoch)\n",
    "\n",
    "                # Handle pruning based on the intermediate value.\n",
    "                if self.trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "            if show_graph:\n",
    "                self.plot_loss_update(epoch, epochs, mb, train_loss_list, valid_loss_list) # for graph\n",
    "                               \n",
    "            epoch_end = timeit.default_timer()\n",
    "            total_time = epoch_end - epoch_start\n",
    "            mins, secs = divmod(total_time, 60)\n",
    "            hours, mins = divmod(mins, 60)\n",
    "            ret_time = f'{int(hours)}:{int(mins)}:{int(secs)}'\n",
    "            mb.write([epoch,f'{train_loss:.6f}',f'{valid_loss:.6f}',\n",
    "                      f'{valid_metric_0_tag:.6f}', f'{valid_metric_1_tag:.6f}', \n",
    "                      f'{valid_metric_0_pos:.6f}', f'{valid_metric_1_pos:.6f}', \n",
    "                      f'{ret_time}'],table=True)\n",
    "            self.log(f'Evaluation time: {ret_time}\\n')\n",
    "#             break\n",
    "            \n",
    "        if return_metric: return best_metric\n",
    "    \n",
    "    def train(self, xy, model, opt, device, sched=None):\n",
    "        model.train()\n",
    "        y_tag = xy.pop('target_tag')\n",
    "        y_pos = xy.pop('target_pos')\n",
    "        x = xy\n",
    "        inputs, target_tag, target_pos = [x_.to(device) for x_ in x.values()], y_tag.to(device), y_pos.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(*inputs)\n",
    "        loss_tag = self.loss_func(out[0], target_tag, x['attention_mask'], model.num_tag)\n",
    "        loss_pos = self.loss_func(out[1], target_pos, x['attention_mask'], model.num_pos)\n",
    "        loss = (loss_tag + loss_pos) / 2\n",
    "        loss.backward()\n",
    "        opt.step()       \n",
    "        if sched is not None:\n",
    "            sched.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def validate(self, xy, model, device):\n",
    "        model.eval()\n",
    "        y_tag = xy.pop('target_tag')\n",
    "        y_pos = xy.pop('target_pos')\n",
    "        x = xy\n",
    "        inputs, target_tag, target_pos = [x_.to(device) for x_ in x.values()], y_tag.to(device), y_pos.to(device)\n",
    "        out = model(*inputs)\n",
    "        loss_tag = self.loss_func(out[0], target_tag, x['attention_mask'], model.num_tag)\n",
    "        loss_pos = self.loss_func(out[1], target_pos, x['attention_mask'], model.num_pos)\n",
    "        loss = (loss_tag + loss_pos) / 2\n",
    "        \n",
    "#         skelarn metrics to be calculated for every item in batch\n",
    "        cleaned_out_tag = out[0].cpu().softmax(2).argmax(dim=2) #[bs, seq_len, hidden_dim(num_labels)] -> [bs, seq_len]\n",
    "        cleaned_out_pos = out[1].cpu().softmax(2).argmax(dim=2) #[bs, seq_len, hidden_dim(num_labels)] -> [bs, seq_len]\n",
    "        all_metric_tag, all_metric_pos = [], []\n",
    "        for i in range(target_tag.shape[0]):\n",
    "#             print(f\"target_tag: {target_tag.cpu()[i]}\")\n",
    "#             print(f\"cleaned_out_tag: {cleaned_out_tag[i]}\")\n",
    "            print(' ')\n",
    "#             truncated_cleaned_out_tag = cleaned_out_tag[i]*x['attention_mask'].cpu()[i]\n",
    "            metric_0_tag = self.process_metric(target_tag, cleaned_out_tag, self.metrics[0], x, i)\n",
    "            metric_1_tag = self.process_metric(target_tag, cleaned_out_tag, self.metrics[1], x, i)\n",
    "            all_metric_tag.append([metric_0_tag, metric_1_tag])\n",
    "#             print(f\"target_pos: {target_pos.cpu()[i][torch.nonzero(x['attention_mask'][i]).flatten()]}\")\n",
    "#             print(f\"cleaned_out_pos: {cleaned_out_pos[i][torch.nonzero(x['attention_mask'][i]).flatten()]}\")\n",
    "            print(' ')\n",
    "#             truncated_cleaned_out_pos = cleaned_out_pos[i]*x['attention_mask'].cpu()[i]\n",
    "            metric_0_pos = self.process_metric(target_pos, cleaned_out_pos, self.metrics[0], x, i)#sklearn metrics are (targ, inp)\n",
    "            metric_1_pos = self.process_metric(target_pos, cleaned_out_pos, self.metrics[1], x, i)\n",
    "            all_metric_pos.append([metric_0_pos, metric_1_pos])\n",
    "        \n",
    "#         print(f\"all_metric_0: {all_metric_0}\")\n",
    "#         print(f\"all_metric_1: {all_metric_1}\")\n",
    "\n",
    "        all_metric_tag = np.array(all_metric_tag)\n",
    "        all_metric_pos = np.array(all_metric_pos)\n",
    "        metrics = ((sum(all_metric_tag[:, 0]) / target_tag.shape[0]),\n",
    "                   (sum(all_metric_tag[:, 1]) / target_tag.shape[0]),\n",
    "                   (sum(all_metric_pos[:, 0]) / target_tag.shape[0]),\n",
    "                   (sum(all_metric_pos[:, 1]) / target_tag.shape[0]))\n",
    "        print(f\"metrics: {metrics}\")\n",
    "        return loss.item(), metrics\n",
    "            \n",
    "    def log(self, message, verbose=False):\n",
    "        if verbose: print(message)\n",
    "        with open(self.log_file, 'a+') as logger_:\n",
    "            logger_.write(f'{message}\\n')\n",
    "            \n",
    "    @staticmethod\n",
    "    def process_metric(target, output, metric, x, i):\n",
    "#         return metric(target[i].cpu()[torch.nonzero(x['attention_mask'][i]).flatten()], \n",
    "#                         output[i][torch.nonzero(x['attention_mask'][i]).flatten()])\n",
    "        return metric(target[i].cpu()[torch.nonzero(target[i]).view(-1)], \n",
    "                        output[i][torch.nonzero(target[i]).view(-1)])\n",
    "           \n",
    "    @staticmethod\n",
    "    def loss_func(out, target, mask, num_labels, func=nn.CrossEntropyLoss()):\n",
    "        '''loss func for NER tasks\n",
    "            out is logit from the model. Shape (bs, seq_len, hidden_dim[num_labels])\n",
    "            target is target from dataloader. Shape (bs, seq_len)\n",
    "        '''\n",
    "        #the mask tell us where non zero tokens are\n",
    "        #the num_labels is used to tell us how many labels(le.classes_) are in the targ\n",
    "        non_zero_tokens = mask.view(-1) == 1 # zeroed token_ids have a mask of 1\n",
    "        ignore_index = func.ignore_index\n",
    "\n",
    "    #     if the token is not zero, select the corresponding target else set ignore_index\n",
    "        cleaned_target = torch.where(non_zero_tokens.to(target.device), \n",
    "                                     target.view(-1), \n",
    "                                     torch.tensor(ignore_index).to(target.device)) #[bs*seq_len]\n",
    "        \n",
    "        cleaned_out = out.view(-1, num_labels) #[bs*seq_len, num_labels]\n",
    "        \n",
    "        loss = func(cleaned_out, cleaned_target)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_loss_update(epoch, epochs, mb, train_loss, valid_loss):\n",
    "        \"\"\" dynamically print the loss plot during the training/validation loop.\n",
    "            expects epoch to start from 1.\n",
    "        \"\"\"\n",
    "        x = range(1, epoch+1)\n",
    "        y = np.concatenate((train_loss, valid_loss))\n",
    "        graphs = [[x,train_loss], [x,valid_loss]]\n",
    "        x_margin = 0.2\n",
    "        y_margin = 0.05\n",
    "        x_bounds = [1-x_margin, epochs+x_margin]\n",
    "        y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
    "\n",
    "        mb.update_graph(np.array(graphs), np.array(x_bounds), np.array(y_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import Bert4NER.config as config\n",
    "import Bert4NER.model.model as model\n",
    "import Bert4NER.utils.utils as utils\n",
    "# import Bert4NER.utils.engine as engine\n",
    "import Bert4NER.dataset.dataset as dataset\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "utils.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "df = pd.read_csv(config.DATA_PATH/'ner_datasetreference.csv', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the foward fill method in pandas to fill all the nans for the each sentence in the `Sentence #` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Sentence: 1\n",
       "1              Sentence: 1\n",
       "2              Sentence: 1\n",
       "3              Sentence: 1\n",
       "4              Sentence: 1\n",
       "                ...       \n",
       "1048570    Sentence: 47959\n",
       "1048571    Sentence: 47959\n",
       "1048572    Sentence: 47959\n",
       "1048573    Sentence: 47959\n",
       "1048574    Sentence: 47959\n",
       "Name: Sentence #, Length: 1048575, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "df['Sentence #'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df['Sentence #'] = df['Sentence #'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we cans ee that there are 47959 sentences in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "len(df['Sentence #'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us encode all the labels for every word in every sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "le_pos = LabelEncoder()\n",
    "le_tag = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files saved!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "utils.save_label_encoders(le_tag=le_tag, le_pos=le_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "le_pos, le_tag = utils.load_label_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df[\"encoded_POS\"] = le_pos.fit_transform(df.POS)\n",
    "df[\"encoded_Tag\"] = le_tag.fit_transform(df.Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "sentences, tags, pos = utils.process_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences[:100]\n",
    "tags = tags[:100]\n",
    "pos = pos[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "len(sentences), len(tags), len(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using a simple train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "train_sentences, valid_sentences, train_tag, valid_tag, train_pos, valid_pos = train_test_split(sentences, tags, pos, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "train_dl = utils.create_loader(train_sentences, train_tag, train_pos, bs=config.TRAIN_BATCH_SIZE)\n",
    "valid_dl = utils.create_loader(valid_sentences, valid_tag, valid_pos, bs=config.TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "modeller = model.EntityModel(len(le_tag.classes_), len(le_pos.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model_params = list(modeller.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# we don't want weight decay for these\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
    "\n",
    "optimizer_params = [\n",
    "    {'params': [p for n, p in model_params if n not in no_decay], \n",
    "    'weight_decay':0.001},\n",
    "    #  no weight decay should be applied\n",
    "    {'params': [p for n, p in model_params if n in no_decay],\n",
    "    'weight_decay':0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "lr = config.LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "optimizer = AdamW(optimizer_params, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "num_train_steps = int(len(df) / config.TRAIN_BATCH_SIZE * config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "                                                num_warmup_steps=0, \n",
    "                                                num_training_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "modeller = model.EntityModel(len(le_tag.classes_), len(le_pos.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# fit = engine.BertFitter(modeller, (train_dl, valid_dl), optimizer, [accuracy_score, partial(f1_score, average='macro')], config.DEVICE, scheduler=scheduler, log_file='training_log.txt')\n",
    "\n",
    "#export\n",
    "fit = BertFitter(modeller, (train_dl, valid_dl), optimizer, [accuracy_score, partial(f1_score, average='macro')], config.DEVICE, scheduler=scheduler, log_file='training_log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.67% [2/30 00:15<03:35]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>tag_accuracy</th>\n",
       "      <th>tag_f1_score</th>\n",
       "      <th>pos_accuracy</th>\n",
       "      <th>pos_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.363626</td>\n",
       "      <td>3.356699</td>\n",
       "      <td>0.031307</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0:0:7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.931072</td>\n",
       "      <td>6.713398</td>\n",
       "      <td>0.062614</td>\n",
       "      <td>0.040408</td>\n",
       "      <td>0.090975</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0:0:7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [2/6 00:01<00:03 0.629]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "metrics: (0.03130711480711481, 0.020203797812493464, 0.04548772685729208, 0.02840903697539853)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "metrics: (0.03130711480711481, 0.020203797812493464, 0.04548772685729208, 0.02840903697539853)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-981857dd537e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'ner_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-ad175a44c3f2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, return_metric, monitor, model_path, show_graph)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TRAINING...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Batch: {ind}, Train loss: {train_loss/ len(self.train_dl)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-ad175a44c3f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, xy, model, opt, device, sched)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mloss_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mloss_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/Bert4NER/Bert4NER/model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     32\u001b[0m         enc_hidden, enc_attn_mask = self.model(input_ids,\n\u001b[1;32m     33\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                            )\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#         enc_hidden: (batch_size, sequence_length, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         )\n\u001b[1;32m    839\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    490\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                 )\n\u001b[1;32m    494\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         )\n\u001b[1;32m    414\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         )\n\u001b[1;32m    351\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "NUM_EPOCHS = 30\n",
    "fit.fit(NUM_EPOCHS, model_path=os.path.join(config.MODEL_PATH/'ner_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.zeros((12,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[[2, 4, 5]] = 1; c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[torch.nonzero(c).flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
